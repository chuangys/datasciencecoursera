---
title: "Practical Machine Learning CourseProject"
author: "Nicole"
date: "2016/05/23"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Step1. Download & assign data

The 1st step is to load the data into R dataset. And assign the training & testing data into variables final_training, final_testing respectively.

Then, for the final_training dataset, we seperate it pre_training & pre_testing (70% & 30%) for modeling.

```{r}
final_training <- read.csv("D:\\Coursera\\Material\\08. Practical Machine Learning\\CourseProject\\pml-training.csv")
final_testing <- read.csv("D:\\Coursera\\Material\\08. Practical Machine Learning\\CourseProject\\pml-testing.csv")

library(lattice);library(ggplot2);library(caret);
set.seed(33833)
inTrain <- createDataPartition(y=final_training$classe,p=0.7,list=FALSE)
pre_training <- final_training[inTrain,]
pre_testing <- final_testing[-inTrain,]
```

## Step2. Data preprocess & Variable selection

Let's do the briefly data explorer. As you can see, there are too many NA or Null variables in the dataset. We remove it from our modeling. 

```{r}
head(pre_training)
colIdx <- c(7:11,37:49,60:68,84:86,102,113:124,140,151:159,160)
training <- final_training[inTrain,colIdx]
testing <- final_training[-inTrain,colIdx]
```

## Step3. Start modeling

Due to performance consideration. Here, I only choose two modeling "rpart" & lda".

```{r}
memory.limit(60000)
set.seed(33833)
rpart <- train(classe~., data=training[,-1],method="rpart")
lda <- train(classe~., data=training[,-1],method="lda")
```

## Step4. Model selection by accurance 

Select to better model by accurance. Here, the rpart get 49% score & lda get 70% score.
Hence, I choose lda as my final model.

```{r}
pred.rpart <- predict(rpart,testing)
pred.lda <- predict(lda,testing)
sum(pred.rpart == testing$classe) / length(testing$classe)
sum(pred.lda == testing$classe) / length(testing$classe)
```
